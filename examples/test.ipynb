{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Neuromah**\n",
    "\n",
    "**A neural network framework that you can use to train your model on!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets.mnist import load_data\n",
    "from Neuromah.src.core import Model\n",
    "from Neuromah.src.layers import Layer_Dense\n",
    "from Neuromah.src.losses.categorical_crossentropy import Loss_CategoricalCrossentropy\n",
    "from Neuromah.src.optimizers import Optimizer_Adam\n",
    "from Neuromah.src.activations import Activation_Softmax, Activation_ReLU\n",
    "from Neuromah.src.metrics.Accuracy_Categorical import Accuracy_Categorical\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Downlaod a dataset**\n",
    "\n",
    "**here we will use the mnist dataset since it's a hello-world for machine-learning and deep learning**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images , train_labels) , (test_images , test_labels) = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **retreive its X and Y shape**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(train_images.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_images.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Naive normalization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = (train_images.astype(np.float32) / 255.0).reshape(train_images.shape[0], -1)\n",
    "test_images = (test_images.astype(np.float32) / 255.0).reshape(test_images.shape[0], -1)\n",
    "train_labels = np.eye(10)[train_labels]\n",
    "test_labels = np.eye(10)[test_labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **spliting the train-validation sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation data\n",
    "val_images = train_images[:10000]\n",
    "val_labels = train_labels[:10000]\n",
    "train_images = train_images[10000:]\n",
    "train_labels = train_labels[10000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Instantiating our model**\n",
    "\n",
    "- **by february 2, 2025 Neuromah only supports the Dense (fully-connected) layer**\n",
    "\n",
    "<br>\n",
    "\n",
    "use model's `add` method for adding the layers to the model in the sequential manner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "\n",
    "model.add(Layer_Dense(n_inputs=784, n_neurons=128, activation=Activation_ReLU()))\n",
    "model.add(Layer_Dense(n_inputs=128, n_neurons=64, activation=Activation_ReLU()))\n",
    "model.add(Layer_Dense(n_inputs=64, n_neurons=10, activation=Activation_Softmax()))\n",
    "model.add(Activation_Softmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Setting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set(\n",
    "    loss=Loss_CategoricalCrossentropy(model=model),\n",
    "    optimizer=Optimizer_Adam(learning_rate=0.001),  # recommended lr value for Adam\n",
    "    accuracy = Accuracy_Categorical(model= model)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Finalizing the model**\n",
    "\n",
    "- always finalize the model before trying to train it\n",
    "- use Model's `finalize` method\n",
    "- similar to `compile` in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.finalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "\n",
    "- train the model using the Model's `train` method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|████████████████████| 1563/1563 [00:13<00:00, 118.12step/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 13.25s, acc: 0.887, loss: 1.629 (data_loss: 1.629, reg_loss: 0.000), lr: 0.0010000\n",
      "validation, acc: 0.888, loss: 1.575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|████████████████████| 1563/1563 [00:15<00:00, 102.92step/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 15.19s, acc: 0.929, loss: 1.540 (data_loss: 1.540, reg_loss: 0.000), lr: 0.0010000\n",
      "validation, acc: 0.926, loss: 1.535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|████████████████████| 1563/1563 [00:19<00:00, 81.66step/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 19.14s, acc: 0.938, loss: 1.524 (data_loss: 1.524, reg_loss: 0.000), lr: 0.0010000\n",
      "validation, acc: 0.930, loss: 1.531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|████████████████████| 1563/1563 [00:24<00:00, 65.04step/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 24.04s, acc: 0.947, loss: 1.514 (data_loss: 1.514, reg_loss: 0.000), lr: 0.0010000\n",
      "validation, acc: 0.942, loss: 1.519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|████████████████████| 1563/1563 [00:24<00:00, 64.96step/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 24.06s, acc: 0.949, loss: 1.510 (data_loss: 1.510, reg_loss: 0.000), lr: 0.0010000\n",
      "validation, acc: 0.944, loss: 1.517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|████████████████████| 1563/1563 [00:24<00:00, 64.78step/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 24.14s, acc: 0.929, loss: 1.507 (data_loss: 1.507, reg_loss: 0.000), lr: 0.0010000\n",
      "validation, acc: 0.925, loss: 1.536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|████████████████████| 1563/1563 [00:24<00:00, 64.41step/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 24.28s, acc: 0.965, loss: 1.504 (data_loss: 1.504, reg_loss: 0.000), lr: 0.0010000\n",
      "validation, acc: 0.959, loss: 1.502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|████████████████████| 1563/1563 [00:23<00:00, 67.40step/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 23.21s, acc: 0.966, loss: 1.503 (data_loss: 1.503, reg_loss: 0.000), lr: 0.0010000\n",
      "validation, acc: 0.958, loss: 1.503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|████████████████████| 1563/1563 [00:20<00:00, 78.01step/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 20.04s, acc: 0.970, loss: 1.499 (data_loss: 1.499, reg_loss: 0.000), lr: 0.0010000\n",
      "validation, acc: 0.963, loss: 1.498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|████████████████████| 1563/1563 [00:20<00:00, 77.78step/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 20.10s, acc: 0.968, loss: 1.498 (data_loss: 1.498, reg_loss: 0.000), lr: 0.0010000\n",
      "validation, acc: 0.962, loss: 1.499\n"
     ]
    }
   ],
   "source": [
    "model.train(train_images, train_labels, epochs=10, batch_size=32, validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.08533674 0.08533674 0.08533674 ... 0.23196932 0.08533674 0.08533674]\n",
      " [0.08533674 0.08533674 0.23196932 ... 0.08533674 0.08533674 0.08533674]\n",
      " [0.08533674 0.23196932 0.08533674 ... 0.08533674 0.08533674 0.08533674]\n",
      " ...\n",
      " [0.08533674 0.08533674 0.08533674 ... 0.08533674 0.08533674 0.08533674]\n",
      " [0.08533674 0.08533674 0.08533674 ... 0.08533674 0.08533674 0.08533674]\n",
      " [0.08533674 0.08533674 0.08533674 ... 0.08533674 0.08533674 0.08533674]]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_images)\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
